{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T03:31:11.930190Z",
     "start_time": "2025-05-11T03:31:07.843822Z"
    }
   },
   "source": [
    "import umap.umap_ as umap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T03:31:11.941688Z",
     "start_time": "2025-05-11T03:31:11.938381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEFAULT_SR = 21000\n",
    "DEFAULT_N_FFT = 2048\n",
    "DEFAULT_HOP_LENGTH = 512\n",
    "DEFAULT_N_MELS = 128"
   ],
   "id": "31c0858efd89d8fa",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T03:31:12.069411Z",
     "start_time": "2025-05-11T03:31:12.063298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def audio_to_melspectrogram(audio_path, sr, n_fft, hop_length, n_mels):\n",
    "    try:\n",
    "        # Calculate fixed shape based on current parameters\n",
    "        duration = 1.0\n",
    "        fixed_shape = (n_mels, int(sr * duration / hop_length) + 1)\n",
    "\n",
    "        # Load with fixed duration (pad/trim as needed)\n",
    "        y, sr = librosa.load(audio_path, sr=sr, duration=duration)\n",
    "        if len(y) < sr * duration:\n",
    "            y = np.pad(y, (0, max(0, int(sr * duration) - len(y))))\n",
    "\n",
    "        # Generate fixed-length spectrogram\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft,\n",
    "                                         hop_length=hop_length,\n",
    "                                         n_mels=n_mels)\n",
    "        log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # Ensure consistent shape\n",
    "        if log_S.shape != fixed_shape:\n",
    "            log_S = log_S[:, :fixed_shape[1]]  # Truncate or pad columns\n",
    "            if log_S.shape[1] < fixed_shape[1]:\n",
    "                log_S = np.pad(log_S, ((0,0), (0,fixed_shape[1]-log_S.shape[1])))\n",
    "\n",
    "        return log_S.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {str(e)}\")\n",
    "        return None"
   ],
   "id": "7248cf83af8c264a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T03:31:12.085165Z",
     "start_time": "2025-05-11T03:31:12.078735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_umap_visualization(sr, n_fft, hop_length, n_mels):\n",
    "    wavs = list(Path(\"mswc_microset/mswc_microset/en/clips\").rglob(\"*.opus\"))\n",
    "    print(f\"Found {len(wavs)} files\")\n",
    "\n",
    "    keyword_dict = defaultdict(list)\n",
    "    for wav in wavs:\n",
    "        label = wav.parts[-2]\n",
    "        if len(keyword_dict[label]) < 15:\n",
    "            keyword_dict[label].append(wav)\n",
    "\n",
    "    spectrograms = []\n",
    "    valid_labels = []\n",
    "    for label, paths in keyword_dict.items():\n",
    "        for path in paths:\n",
    "            spec = audio_to_melspectrogram(str(path), sr, n_fft, hop_length, n_mels)\n",
    "            if spec is not None:\n",
    "                spectrograms.append(spec)\n",
    "                valid_labels.append(label)\n",
    "\n",
    "    if not spectrograms:\n",
    "        print(\"No valid spectrograms generated!\")\n",
    "        return\n",
    "\n",
    "    spectrograms = np.stack(spectrograms)\n",
    "    print(f\"Final array shape: {spectrograms.shape}\")\n",
    "\n",
    "    # Standardize and project\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(spectrograms)\n",
    "    embedding = umap.UMAP(random_state=42).fit_transform(scaled)\n",
    "\n",
    "    # Plot\n",
    "    df = pd.DataFrame({\n",
    "        'x': embedding[:,0],\n",
    "        'y': embedding[:,1],\n",
    "        'keyword': valid_labels\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    sns.scatterplot(\n",
    "        x='x', y='y',\n",
    "        hue='keyword',\n",
    "        data=df,\n",
    "        palette=sns.color_palette('hls', len(set(valid_labels))),\n",
    "        s=100,\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.title(f\"UMAP of {len(valid_labels)} audio samples (SR={sr}, N_FFT={n_fft}, Hop={hop_length}, Mels={n_mels})\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "2cffb035b6de5ff1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T03:31:12.131686Z",
     "start_time": "2025-05-11T03:31:12.103543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "interact_manual(\n",
    "    create_umap_visualization,\n",
    "    sr=widgets.IntSlider(min=8000, max=44100, step=1000, value=DEFAULT_SR, description=\"Sample Rate\"),\n",
    "    n_fft=widgets.IntSlider(min=256, max=4096, step=256, value=DEFAULT_N_FFT, description=\"N_FFT\"),\n",
    "    hop_length=widgets.IntSlider(min=64, max=1024, step=64, value=DEFAULT_HOP_LENGTH, description=\"Hop Length\"),\n",
    "    n_mels=widgets.IntSlider(min=32, max=256, step=32, value=DEFAULT_N_MELS, description=\"N Mels\")\n",
    ")"
   ],
   "id": "6b38380d35d5f0ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactive(children=(IntSlider(value=21000, description='Sample Rate', max=44100, min=8000, step=1000), IntSlâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2eba7d45463d45cba71ae365f3018280"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.create_umap_visualization(sr, n_fft, hop_length, n_mels)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
